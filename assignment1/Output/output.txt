Conda uses environments to load different sets of Python packages
type conda env list to see the environments availible.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/05/07 17:43:49 INFO SparkContext: Running Spark version 3.2.1
22/05/07 17:43:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/05/07 17:43:50 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
22/05/07 17:43:50 INFO ResourceUtils: ==============================================================
22/05/07 17:43:50 INFO ResourceUtils: No custom resources configured for spark.driver.
22/05/07 17:43:50 INFO ResourceUtils: ==============================================================
22/05/07 17:43:50 INFO SparkContext: Submitted application: Assignment1
22/05/07 17:43:50 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/05/07 17:43:50 INFO ResourceProfile: Limiting resource is cpu
22/05/07 17:43:50 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/05/07 17:43:50 INFO SecurityManager: Changing view acls to: acp21kc
22/05/07 17:43:50 INFO SecurityManager: Changing modify acls to: acp21kc
22/05/07 17:43:50 INFO SecurityManager: Changing view acls groups to: 
22/05/07 17:43:50 INFO SecurityManager: Changing modify acls groups to: 
22/05/07 17:43:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acp21kc); groups with view permissions: Set(); users  with modify permissions: Set(acp21kc); groups with modify permissions: Set()
22/05/07 17:43:51 INFO Utils: Successfully started service 'sparkDriver' on port 46876.
22/05/07 17:43:51 INFO SparkEnv: Registering MapOutputTracker
22/05/07 17:43:51 INFO SparkEnv: Registering BlockManagerMaster
22/05/07 17:43:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/05/07 17:43:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/05/07 17:43:51 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/05/07 17:43:51 INFO DiskBlockManager: Created local directory at /mnt/fastdata/acp21kc/blockmgr-2b8ba6a5-504a-4a7e-b98c-93b65763bfcb
22/05/07 17:43:52 INFO MemoryStore: MemoryStore started with capacity 4.1 GiB
22/05/07 17:43:52 INFO SparkEnv: Registering OutputCommitCoordinator
22/05/07 17:43:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/05/07 17:43:52 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://sharc-node159.shef.ac.uk:4040
22/05/07 17:43:53 INFO Executor: Starting executor ID driver on host sharc-node159.shef.ac.uk
22/05/07 17:43:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45994.
22/05/07 17:43:53 INFO NettyBlockTransferService: Server created on sharc-node159.shef.ac.uk:45994
22/05/07 17:43:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/05/07 17:43:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, sharc-node159.shef.ac.uk, 45994, None)
22/05/07 17:43:53 INFO BlockManagerMasterEndpoint: Registering block manager sharc-node159.shef.ac.uk:45994 with 4.1 GiB RAM, BlockManagerId(driver, sharc-node159.shef.ac.uk, 45994, None)
22/05/07 17:43:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, sharc-node159.shef.ac.uk, 45994, None)
22/05/07 17:43:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, sharc-node159.shef.ac.uk, 45994, None)
/home/acp21kc/.conda/envs/myspark/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.
  FutureWarning
22/05/07 17:43:54 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/05/07 17:43:55 INFO SharedState: Warehouse path is 'file:/data/acp21kc/ScalableML/Assignment1/HPC/spark-warehouse'.
-------------------------------------------------------------
Logistic Regression:
Logistic Regression Accuracy = 0.500948 
best regparam:  0.001
best maxIter:  10
best elasticNetParam:  0.0
-------------------------------------------------------------
NN:
NN Accuracy = 0.501048 
best maxIter:  10
best layers:  [128, 30, 10, 2]
best stepSize:  0.03
-------------------------------------------------------------
Random Forest model:
Random Forest Accuracy = 0.499995 
best maxBins:  16
best maxDepth:  7
best numTrees:  20
-------------------------------------------------------------
Logistic Regression full model on 5 cores:
Accuracy of lr full model:  0.500763
Area under curve of lr full model:  0.5007929578340675
time for training:  94.82329154014587 seconds
time for testing:  13.5228111743927 seconds
-------------------------------------------------------------
NN full model on 5 cores:
Accuracy of nn full model:  0.499867
Area under curve of lr full model:  0.4999162494990357
time for training:  212.53309965133667 seconds
time for testing:  15.430031538009644 seconds
-------------------------------------------------------------
Random Forest full model on 5 cores:
Accuracy of nn full model:  0.500349
Area under curve of lr full model:  0.5003922997701953
time for training:  157.49579858779907 seconds
time for testing:  14.55146312713623 seconds
-------------------------------------------------------------
Logistic Regression full model on 10 cores:
Accuracy of lr full model:  0.500763
Area under curve of lr full model:  0.5007929578340675
time for training:  66.36491107940674 seconds
time for testing:  7.571428298950195 seconds
-------------------------------------------------------------
NN full model on 10 cores:
Accuracy of nn full model:  0.499867
Area under curve of lr full model:  0.4999162494990357
time for training:  146.98479890823364 seconds
time for testing:  9.120765924453735 seconds
-------------------------------------------------------------
Random Forest full model on 10 cores:
Accuracy of nn full model:  0.500349
Area under curve of lr full model:  0.5003922997701953
time for training:  108.17831015586853 seconds
time for testing:  8.465364933013916 seconds
